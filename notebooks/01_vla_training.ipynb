{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "name": "01_vla_training.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": { "id": "title" },
      "source": [
        "# VLA Fine-Tuning: SmolVLA on Meta-World\n",
        "\n",
        "This notebook fine-tunes [SmolVLA](https://huggingface.co/lerobot/smolvla_base) (450M-param Vision-Language-Action model) on [Meta-World](https://github.com/Farama-Foundation/Metaworld) manipulation tasks.\n",
        "\n",
        "We run a **3-way comparison**:\n",
        "1. **Random init** — train SmolVLA from scratch (architecture only, no pretrained weights)\n",
        "2. **Pretrained zero-shot** — evaluate the pretrained SmolVLA directly (no fine-tuning)\n",
        "3. **Fine-tuned** — adapt pretrained SmolVLA to Meta-World tasks\n",
        "\n",
        "**Requirements**: Colab Pro+ with A100 GPU. Training takes ~5 hours per run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": { "id": "clone_header" },
      "source": [
        "## 0. Clone project repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "id": "clone_repo" },
      "source": [
        "!git clone https://github.com/vivpra89/VLA_BD.git /content/VLA_BD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": { "id": "setup_header" },
      "source": [
        "## 1. Setup: Install Conda + LeRobot + SmolVLA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "id": "install_conda" },
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "# NOTE: Runtime will restart automatically after this cell. That's expected."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": { "id": "install_lerobot" },
      "source": [
        "!git clone https://github.com/huggingface/lerobot.git /content/lerobot\n",
        "!conda install ffmpeg=7.1.1 -c conda-forge -y\n",
        "%cd /content/lerobot\n",
        "!pip install -e \".[smolvla]\"\n",
        "!pip install \"gymnasium==1.1.0\" metaworld wandb matplotlib\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": { "id": "wandb_header" },
      "source": [
        "## 2. (Optional) Login to Weights & Biases for training curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "id": "wandb_login" },
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": { "id": "tasks_header" },
      "source": [
        "## 3. Pick Meta-World tasks\n",
        "\n",
        "We select 3 diverse tasks from the MT50 suite:\n",
        "- `assembly-v3` — insert a peg into a hole\n",
        "- `dial-turn-v3` — turn a dial\n",
        "- `handle-press-side-v3` — press a handle from the side\n",
        "\n",
        "These test different manipulation skills: insertion, rotation, and pressing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "id": "config" },
      "source": [
        "import os\n",
        "os.environ[\"TASKS\"] = \"assembly-v3,dial-turn-v3,handle-press-side-v3\"\n",
        "os.environ[\"DATASET\"] = \"lerobot/metaworld_mt50\"\n",
        "os.environ[\"OUTPUT_BASE\"] = \"/content/outputs\"\n",
        "\n",
        "TASKS = os.environ[\"TASKS\"]\n",
        "DATASET = os.environ[\"DATASET\"]\n",
        "OUTPUT_BASE = os.environ[\"OUTPUT_BASE\"]\n",
        "STEPS_FINETUNE = 20000\n",
        "STEPS_SCRATCH = 20000\n",
        "BATCH_SIZE = 64\n",
        "EVAL_FREQ = 2000\n",
        "EVAL_EPISODES = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": { "id": "finetune_header" },
      "source": [
        "## 4. Run 1: Fine-tune pretrained SmolVLA\n",
        "\n",
        "Start from `lerobot/smolvla_base` (pretrained on real SO100 robot data) and adapt to Meta-World.\n",
        "This is the standard VLA workflow — take a foundation model, fine-tune on your target domain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "id": "train_finetuned" },
      "source": [
        "%cd /content/lerobot\n",
        "!lerobot-train \\\n",
        "    --policy.path=lerobot/smolvla_base \\\n",
        "    --dataset.repo_id=lerobot/metaworld_mt50 \\\n",
        "    --env.type=metaworld \\\n",
        "    --env.task=assembly-v3,dial-turn-v3,handle-press-side-v3 \\\n",
        "    --batch_size=64 \\\n",
        "    --steps=20000 \\\n",
        "    --eval.n_episodes=5 \\\n",
        "    --eval_freq=2000 \\\n",
        "    --save_freq=2000 \\\n",
        "    --output_dir=/content/outputs/finetuned \\\n",
        "    --job_name=smolvla_finetuned \\\n",
        "    --policy.device=cuda \\\n",
        "    --wandb.enable=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": { "id": "scratch_header" },
      "source": [
        "## 5. Run 2: Train from scratch (random init) — OPTIONAL\n",
        "\n",
        "Same architecture, same training, but **no pretrained weights**. This shows how much the pretrained VLM features help.\n",
        "\n",
        "**Skip this cell if you want results faster.** You still get a 2-way comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "id": "train_scratch" },
      "source": [
        "%cd /content/lerobot\n",
        "!lerobot-train \\\n",
        "    --policy.type=smolvla \\\n",
        "    --dataset.repo_id=lerobot/metaworld_mt50 \\\n",
        "    --env.type=metaworld \\\n",
        "    --env.task=assembly-v3,dial-turn-v3,handle-press-side-v3 \\\n",
        "    --batch_size=64 \\\n",
        "    --steps=20000 \\\n",
        "    --eval.n_episodes=5 \\\n",
        "    --eval_freq=2000 \\\n",
        "    --save_freq=2000 \\\n",
        "    --output_dir=/content/outputs/scratch \\\n",
        "    --job_name=smolvla_scratch \\\n",
        "    --policy.device=cuda \\\n",
        "    --wandb.enable=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": { "id": "eval_header" },
      "source": [
        "## 6. Evaluate all conditions\n",
        "\n",
        "Run evaluation on each task for:\n",
        "- **Pretrained zero-shot** (no training on Meta-World)\n",
        "- **Fine-tuned** (best checkpoint)\n",
        "- **From scratch** (best checkpoint, if trained)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "id": "eval_all" },
      "source": [
        "import subprocess, os\n",
        "\n",
        "conditions = {\n",
        "    \"pretrained_zeroshot\": \"lerobot/smolvla_base\",\n",
        "    \"finetuned\": \"/content/outputs/finetuned/checkpoints/last/pretrained_model\",\n",
        "}\n",
        "\n",
        "scratch_path = \"/content/outputs/scratch/checkpoints/last/pretrained_model\"\n",
        "if os.path.exists(scratch_path):\n",
        "    conditions[\"from_scratch\"] = scratch_path\n",
        "\n",
        "tasks = [\"assembly-v3\", \"dial-turn-v3\", \"handle-press-side-v3\"]\n",
        "results = {}\n",
        "\n",
        "for cond_name, policy_path in conditions.items():\n",
        "    results[cond_name] = {}\n",
        "    for task in tasks:\n",
        "        print(f\"\\n--- Evaluating {cond_name} on {task} ---\")\n",
        "        eval_dir = f\"/content/outputs/eval/{cond_name}/{task}\"\n",
        "        cmd = f\"\"\"cd /content/lerobot && lerobot-eval \\\n",
        "            --policy.path={policy_path} \\\n",
        "            --env.type=metaworld \\\n",
        "            --env.task={task} \\\n",
        "            --eval.batch_size=1 \\\n",
        "            --eval.n_episodes=10 \\\n",
        "            --output_dir={eval_dir}\"\"\"\n",
        "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "        print(result.stdout[-500:] if result.stdout else \"No stdout\")\n",
        "        if result.returncode != 0:\n",
        "            print(f\"Error: {result.stderr[-500:]}\")\n",
        "            results[cond_name][task] = 0.0\n",
        "        else:\n",
        "            results[cond_name][task] = \"see eval_dir\"\n",
        "\n",
        "print(\"\\n=== All Results ===\")\n",
        "for cond, task_results in results.items():\n",
        "    print(f\"\\n{cond}:\")\n",
        "    for task, score in task_results.items():\n",
        "        print(f\"  {task}: {score}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": { "id": "viz_header" },
      "source": [
        "## 7. Visualize training curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "id": "visualize" },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import json, glob, os\n",
        "import numpy as np\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for idx, (label, output_dir) in enumerate([\n",
        "    (\"Fine-tuned (pretrained init)\", \"/content/outputs/finetuned\"),\n",
        "    (\"From scratch (random init)\", \"/content/outputs/scratch\"),\n",
        "]):\n",
        "    log_files = glob.glob(os.path.join(output_dir, \"**/*.json\"), recursive=True)\n",
        "    if not log_files:\n",
        "        print(f\"No log files found for {label} in {output_dir}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Log files for {label}: {log_files}\")\n",
        "    for log_file in log_files:\n",
        "        try:\n",
        "            with open(log_file) as f:\n",
        "                logs = [json.loads(line) for line in f if line.strip()]\n",
        "            steps = [l[\"step\"] for l in logs if \"loss\" in l]\n",
        "            losses = [l[\"loss\"] for l in logs if \"loss\" in l]\n",
        "            if steps:\n",
        "                color = \"tab:blue\" if idx == 0 else \"tab:orange\"\n",
        "                axes[0].plot(steps, losses, label=label, color=color, alpha=0.8)\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print(f\"  Could not parse {log_file}: {e}\")\n",
        "\n",
        "axes[0].set_xlabel(\"Training Steps\")\n",
        "axes[0].set_ylabel(\"Loss\")\n",
        "axes[0].set_title(\"Training Loss: Fine-tuned vs From Scratch\")\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "ax2 = axes[1]\n",
        "task_names = [\"assembly\", \"dial-turn\", \"handle-press\"]\n",
        "x = np.arange(len(task_names))\n",
        "width = 0.25\n",
        "\n",
        "scratch_rates = [0.0, 0.0, 0.0]\n",
        "zeroshot_rates = [0.0, 0.0, 0.0]\n",
        "finetuned_rates = [0.0, 0.0, 0.0]\n",
        "\n",
        "ax2.bar(x - width, scratch_rates, width, label=\"From scratch\", color=\"tab:red\", alpha=0.8)\n",
        "ax2.bar(x, zeroshot_rates, width, label=\"Pretrained (zero-shot)\", color=\"tab:orange\", alpha=0.8)\n",
        "ax2.bar(x + width, finetuned_rates, width, label=\"Fine-tuned\", color=\"tab:green\", alpha=0.8)\n",
        "\n",
        "ax2.set_xlabel(\"Task\")\n",
        "ax2.set_ylabel(\"Success Rate\")\n",
        "ax2.set_title(\"3-Way Comparison: Success Rate by Task\")\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(task_names)\n",
        "ax2.legend()\n",
        "ax2.set_ylim(0, 1.0)\n",
        "ax2.grid(True, alpha=0.3, axis=\"y\")\n",
        "\n",
        "plt.tight_layout()\n",
        "os.makedirs(\"/content/outputs\", exist_ok=True)\n",
        "plt.savefig(\"/content/outputs/training_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(\"Saved to /content/outputs/training_comparison.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": { "id": "upload_header" },
      "source": [
        "## 8. Upload best checkpoint to HuggingFace Hub\n",
        "\n",
        "Save the fine-tuned model so we can load it in the introspection notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "id": "hf_login" },
      "source": [
        "!huggingface-cli login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": { "id": "hf_upload" },
      "source": [
        "import os\n",
        "HF_USER = os.environ.get(\"HF_USER\", \"YOUR_USERNAME\")\n",
        "\n",
        "!huggingface-cli upload {HF_USER}/smolvla-metaworld-finetuned \\\n",
        "    /content/outputs/finetuned/checkpoints/last/pretrained_model\n",
        "\n",
        "print(f\"\\nModel uploaded to:\")\n",
        "print(f\"  https://huggingface.co/{HF_USER}/smolvla-metaworld-finetuned\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
