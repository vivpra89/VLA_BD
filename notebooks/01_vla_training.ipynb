{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VLA Fine-Tuning: SmolVLA on Meta-World\n",
    "\n",
    "This notebook fine-tunes [SmolVLA](https://huggingface.co/lerobot/smolvla_base) (450M-param Vision-Language-Action model) on [Meta-World](https://github.com/Farama-Foundation/Metaworld) manipulation tasks.\n",
    "\n",
    "We run a **3-way comparison**:\n",
    "1. **Random init** — train SmolVLA from scratch (architecture only, no pretrained weights)\n",
    "2. **Pretrained zero-shot** — evaluate the pretrained SmolVLA directly (no fine-tuning)\n",
    "3. **Fine-tuned** — adapt pretrained SmolVLA to Meta-World tasks\n",
    "\n",
    "**Requirements**: Colab Pro+ with A100 GPU. Training takes ~5 hours per run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Install Conda + LeRobot + SmolVLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()\n",
    "# NOTE: Runtime will restart automatically after this cell. That's expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/huggingface/lerobot.git\n",
    "!conda install ffmpeg=7.1.1 -c conda-forge -y\n",
    "!cd lerobot && pip install -e \".[smolvla]\"\n",
    "!pip install \"gymnasium==1.1.0\" metaworld wandb matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (Optional) Login to Weights & Biases for training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pick Meta-World tasks\n",
    "\n",
    "We select 3 diverse tasks from the MT50 suite:\n",
    "- `assembly-v3` — insert a peg into a hole\n",
    "- `dial-turn-v3` — turn a dial\n",
    "- `handle-press-side-v3` — press a handle from the side\n",
    "\n",
    "These test different manipulation skills: insertion, rotation, and pressing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS = \"assembly-v3,dial-turn-v3,handle-press-side-v3\"\n",
    "DATASET = \"lerobot/metaworld_mt50\"\n",
    "STEPS_FINETUNE = 20000\n",
    "STEPS_SCRATCH = 20000\n",
    "BATCH_SIZE = 64\n",
    "EVAL_FREQ = 2000\n",
    "EVAL_EPISODES = 5\n",
    "OUTPUT_BASE = \"/content/outputs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run 1: Fine-tune pretrained SmolVLA\n",
    "\n",
    "Start from `lerobot/smolvla_base` (pretrained on real SO100 robot data) and adapt to Meta-World.\n",
    "This is the standard VLA workflow — take a foundation model, fine-tune on your target domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd lerobot && python lerobot/scripts/train.py \\\n",
    "    --policy.path=lerobot/smolvla_base \\\n",
    "    --dataset.repo_id={DATASET} \\\n",
    "    --env.type=metaworld \\\n",
    "    --env.task={TASKS} \\\n",
    "    --batch_size={BATCH_SIZE} \\\n",
    "    --steps={STEPS_FINETUNE} \\\n",
    "    --eval.n_episodes={EVAL_EPISODES} \\\n",
    "    --eval_freq={EVAL_FREQ} \\\n",
    "    --save_freq={EVAL_FREQ} \\\n",
    "    --output_dir={OUTPUT_BASE}/finetuned \\\n",
    "    --job_name=smolvla_finetuned \\\n",
    "    --policy.device=cuda \\\n",
    "    --wandb.enable=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run 2: Train from scratch (random init)\n",
    "\n",
    "Same architecture, same training, but **no pretrained weights**. This shows how much the pretrained VLM features help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd lerobot && python lerobot/scripts/train.py \\\n",
    "    --policy.type=smolvla \\\n",
    "    --dataset.repo_id={DATASET} \\\n",
    "    --env.type=metaworld \\\n",
    "    --env.task={TASKS} \\\n",
    "    --batch_size={BATCH_SIZE} \\\n",
    "    --steps={STEPS_SCRATCH} \\\n",
    "    --eval.n_episodes={EVAL_EPISODES} \\\n",
    "    --eval_freq={EVAL_FREQ} \\\n",
    "    --save_freq={EVAL_FREQ} \\\n",
    "    --output_dir={OUTPUT_BASE}/scratch \\\n",
    "    --job_name=smolvla_scratch \\\n",
    "    --policy.device=cuda \\\n",
    "    --wandb.enable=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate all 3 conditions\n",
    "\n",
    "Run evaluation on each task for:\n",
    "- **Pretrained zero-shot** (no training on Meta-World)\n",
    "- **Fine-tuned** (best checkpoint)\n",
    "- **From scratch** (best checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, json, os\n",
    "\n",
    "conditions = {\n",
    "    \"pretrained_zeroshot\": \"lerobot/smolvla_base\",\n",
    "    \"finetuned\": f\"{OUTPUT_BASE}/finetuned/checkpoints/last/pretrained_model\",\n",
    "    \"from_scratch\": f\"{OUTPUT_BASE}/scratch/checkpoints/last/pretrained_model\",\n",
    "}\n",
    "\n",
    "tasks = TASKS.split(\",\")\n",
    "results = {}\n",
    "\n",
    "for cond_name, policy_path in conditions.items():\n",
    "    if not os.path.exists(policy_path) and \"/\" not in policy_path[:5]:\n",
    "        print(f\"Skipping {cond_name}: checkpoint not found at {policy_path}\")\n",
    "        continue\n",
    "    results[cond_name] = {}\n",
    "    for task in tasks:\n",
    "        print(f\"\\n--- Evaluating {cond_name} on {task} ---\")\n",
    "        eval_dir = f\"{OUTPUT_BASE}/eval/{cond_name}/{task}\"\n",
    "        cmd = [\n",
    "            \"python\", \"lerobot/scripts/eval.py\",\n",
    "            f\"--policy.path={policy_path}\",\n",
    "            \"--env.type=metaworld\",\n",
    "            f\"--env.task={task}\",\n",
    "            \"--eval.batch_size=1\",\n",
    "            \"--eval.n_episodes=10\",\n",
    "            f\"--output_dir={eval_dir}\",\n",
    "        ]\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, cwd=\"/content/lerobot\")\n",
    "        print(result.stdout[-500:] if result.stdout else \"No stdout\")\n",
    "        if result.returncode != 0:\n",
    "            print(f\"Error: {result.stderr[-500:]}\")\n",
    "            results[cond_name][task] = 0.0\n",
    "        else:\n",
    "            # Parse success rate from output (adjust parsing based on actual output format)\n",
    "            results[cond_name][task] = \"check eval_dir for results\"\n",
    "\n",
    "print(\"\\n=== All Results ===\")\n",
    "for cond, task_results in results.items():\n",
    "    print(f\"\\n{cond}:\")\n",
    "    for task, score in task_results.items():\n",
    "        print(f\"  {task}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json, glob, os\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for idx, (label, output_dir) in enumerate([\n",
    "    (\"Fine-tuned (pretrained init)\", f\"{OUTPUT_BASE}/finetuned\"),\n",
    "    (\"From scratch (random init)\", f\"{OUTPUT_BASE}/scratch\"),\n",
    "]):\n",
    "    log_file = os.path.join(output_dir, \"training_log.json\")\n",
    "    if not os.path.exists(log_file):\n",
    "        # Try reading from W&B or CSV logs instead\n",
    "        log_files = glob.glob(os.path.join(output_dir, \"**/*.json\"), recursive=True)\n",
    "        print(f\"Available log files for {label}: {log_files}\")\n",
    "        continue\n",
    "\n",
    "    with open(log_file) as f:\n",
    "        logs = [json.loads(line) for line in f]\n",
    "\n",
    "    steps = [l[\"step\"] for l in logs if \"loss\" in l]\n",
    "    losses = [l[\"loss\"] for l in logs if \"loss\" in l]\n",
    "\n",
    "    color = \"tab:blue\" if idx == 0 else \"tab:orange\"\n",
    "    axes[0].plot(steps, losses, label=label, color=color, alpha=0.8)\n",
    "\n",
    "axes[0].set_xlabel(\"Training Steps\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Training Loss: Fine-tuned vs From Scratch\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bar chart for success rates (fill in after eval)\n",
    "# Placeholder data — replace with actual eval results\n",
    "ax2 = axes[1]\n",
    "task_names = [\"assembly\", \"dial-turn\", \"handle-press\"]\n",
    "x = np.arange(len(task_names))\n",
    "width = 0.25\n",
    "\n",
    "# Replace these with actual success rates from evaluation\n",
    "scratch_rates = [0.0, 0.0, 0.0]  # Update after eval\n",
    "zeroshot_rates = [0.0, 0.0, 0.0]  # Update after eval\n",
    "finetuned_rates = [0.0, 0.0, 0.0]  # Update after eval\n",
    "\n",
    "ax2.bar(x - width, scratch_rates, width, label=\"From scratch\", color=\"tab:red\", alpha=0.8)\n",
    "ax2.bar(x, zeroshot_rates, width, label=\"Pretrained (zero-shot)\", color=\"tab:orange\", alpha=0.8)\n",
    "ax2.bar(x + width, finetuned_rates, width, label=\"Fine-tuned\", color=\"tab:green\", alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel(\"Task\")\n",
    "ax2.set_ylabel(\"Success Rate\")\n",
    "ax2.set_title(\"3-Way Comparison: Success Rate by Task\")\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(task_names)\n",
    "ax2.legend()\n",
    "ax2.set_ylim(0, 1.0)\n",
    "ax2.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_BASE}/training_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"Saved to {OUTPUT_BASE}/training_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Upload best checkpoint to HuggingFace Hub\n",
    "\n",
    "Save the fine-tuned model so we can load it in the introspection notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HF_USER = os.environ.get(\"HF_USER\", \"YOUR_USERNAME\")\n",
    "\n",
    "!huggingface-cli upload {HF_USER}/smolvla-metaworld-finetuned \\\n",
    "    {OUTPUT_BASE}/finetuned/checkpoints/last/pretrained_model\n",
    "\n",
    "!huggingface-cli upload {HF_USER}/smolvla-metaworld-scratch \\\n",
    "    {OUTPUT_BASE}/scratch/checkpoints/last/pretrained_model\n",
    "\n",
    "print(f\"\\nModels uploaded to:\")\n",
    "print(f\"  https://huggingface.co/{HF_USER}/smolvla-metaworld-finetuned\")\n",
    "print(f\"  https://huggingface.co/{HF_USER}/smolvla-metaworld-scratch\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
